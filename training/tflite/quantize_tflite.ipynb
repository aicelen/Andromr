{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize tflite models\n",
    "This quantizes tflite models to int8 to speed up inference and reduce size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm89sXIbvM9w"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow jax jaxlib\n",
    "!pip install ai-edge-quantizer-nightly\n",
    "!pip install ai-edge-model-explorer\n",
    "!pip install ai-edge-litert-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aiTX7VX7vRrD"
   },
   "outputs": [],
   "source": [
    "from ai_edge_quantizer import quantizer\n",
    "from ai_edge_quantizer import recipe\n",
    "\n",
    "qt = quantizer.Quantizer(\n",
    "    \"cnn_encoder_pytorch_model_236-922ad08f8895f6d9c0ae61954cd78a021ff950a7_float32.tflite\"\n",
    ")\n",
    "qt.load_quantization_recipe(recipe.dynamic_wi8_afp32())\n",
    "qt.quantize().export_model(\n",
    "    \"cnn_encoder_pytorch_model_236-922ad08f8895f6d9c0ae61954cd78a021ff950a7.tflite\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
